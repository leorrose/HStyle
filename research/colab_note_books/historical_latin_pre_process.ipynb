{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modern_arab_pre_process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHjpnh7rdXjV"
      },
      "source": [
        "# Historical style generator\n",
        "##### Students – Leor Ariel Rose, Yahav Bar David\n",
        "##### Academic advisor - Dr. Irina Rabaev\n",
        "\n",
        "This notebook contains our modern arab pre process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLRvTQAqGp1n"
      },
      "source": [
        "Next we will import all necessary libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLJ7RrVdY59"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-og0jVmd5hO"
      },
      "source": [
        "Next lets mount our drive with our data and folders to save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZe2pBYxd_da",
        "outputId": "a097f406-0cdb-4a7c-f3dc-a907285d286f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRIjYTq7dmWo"
      },
      "source": [
        "Next will define our paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9uD9nDdsWZ"
      },
      "source": [
        "arab_modern_data_documents = \"/content/drive/My Drive/final_project/raw_data/modern_arab/documents\"\n",
        "arab_modern_data_sentences = \"/content/drive/My Drive/final_project/raw_data/modern_arab/sentences\"\n",
        "arab_clean_modern_data_documents = \"/content/drive/My Drive/final_project/clean_data/modern_arab/documents\"\n",
        "arab_clean_modern_data_sentences = \"/content/drive/My Drive/final_project/clean_data/modern_arab/sentences\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEfCekNZepEX"
      },
      "source": [
        "Now we will empty our previous preprocessed documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J95mGOVieoNN"
      },
      "source": [
        "# empty old clean data\n",
        "if os.path.exists(arab_clean_modern_data_documents):\n",
        "    shutil.rmtree(arab_clean_modern_data_documents)\n",
        "    \n",
        "os.mkdir(arab_clean_modern_data_documents)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4npcQ1HHeptx"
      },
      "source": [
        "Next we will pre process modern arab data to create document images.\n",
        "For documents - images need to be change to type png."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjUdgzJSeqJR"
      },
      "source": [
        "# clean each image in modern english folder\n",
        "for img_file in tqdm(os.listdir(arab_modern_data_documents), position=0, leave=True):\n",
        "    img_name:str\n",
        "    img_type:str\n",
        "    img_name, img_type = os.path.splitext(img_file)\n",
        "                \n",
        "    # full path of image\n",
        "    img_full_path:str = f\"{arab_modern_data_documents}/{img_file}\"\n",
        "                \n",
        "    # path to save finished processed image\n",
        "    img_new_full_path:str = f\"{arab_clean_modern_data_documents}/{img_name}.png\"\n",
        "\n",
        "    # step 1 - open image\n",
        "    img: np.ndarray = cv.imread(img_full_path)\n",
        "    \n",
        "    # save image as png\n",
        "    cv.imwrite(img_new_full_path, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_kpqFQeoN-B"
      },
      "source": [
        "Now we will empty our previous preprocessed sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51EuHbKfoOoU"
      },
      "source": [
        "# empty old clean data\n",
        "if os.path.exists(arab_clean_modern_data_sentences):\n",
        "    shutil.rmtree(arab_clean_modern_data_sentences)\n",
        "\n",
        "os.mkdir(arab_clean_modern_data_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtQhfvkoV5Mr"
      },
      "source": [
        "Next we will pre process modern arab sentences to create sentences images.\n",
        "For sentences - images need to be change to type png.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqfnJNgCKPDt",
        "outputId": "fbada4d0-6ab7-4137-ba37-604938d396cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# clean each image in modern english folder\n",
        "for img_file in tqdm(os.listdir(arab_modern_data_sentences), position=0, leave=True):\n",
        "    img_name:str\n",
        "    img_type:str\n",
        "    img_name, img_type = os.path.splitext(img_file)\n",
        "                \n",
        "    # full path of image\n",
        "    img_full_path:str = f\"{arab_modern_data_sentences}/{img_file}\"\n",
        "                \n",
        "    # path to save finished processed image\n",
        "    img_new_full_path:str = f\"{arab_clean_modern_data_sentences}/{img_name}.png\"\n",
        "\n",
        "    # step 1 - open image\n",
        "    img: np.ndarray = cv.imread(img_full_path)\n",
        "    \n",
        "    # save image as png\n",
        "    cv.imwrite(img_new_full_path, img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13435/13435 [1:07:38<00:00,  3.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}